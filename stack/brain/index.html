<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta http-equiv="Content-Security-Policy" content="default-src 'self';
script-src 'self';
style-src 'self' https://fonts.googleapis.com ;
img-src 'self' data: https://i.pravatar.cc;
connect-src 'self' https://*.supabase.co;
font-src 'self' https://fonts.gstatic.com; frame-ancestors 'none';"><script type="module" src="/_astro/Layout.astro_astro_type_script_index_0_lang.DpBaZWZO.js"></script><meta name="viewport" content="width=device-width"><link rel="icon" type="image/svg+xml" href="/favicon.ico"><meta name="generator" content="Astro v5.16.10"><title>The Reasoning Brain | Curated Research, News &amp; Implementation Stack.</title><meta name="description" content="Curated Research, News &#38; Implementation Stack."><meta property="og:title" content="The Reasoning Brain | Curated Research, News &#38; Implementation Stack."><meta property="og:description" content="Curated Research, News &#38; Implementation Stack."><meta property="og:type" content="website"><meta name="google-site-verification" content="TudBB1tWAlqMcSVbAgr2cOJBSwGoLAwsrt3FEe0w7Ds"><script type="module">(window.top!==window.self||window.location.hostname==="agentsicworld.pages.dev")&&(window.top.location.href="https://www.agentsicworld.com");</script><link rel="stylesheet" href="/_astro/about.Bd3R9k1w.css">
<link rel="stylesheet" href="/_astro/_slug_.CKB9bavk.css"></head> <body>  <header class="site-header"> <div class="nav-container"> <nav class="main-nav"> <ul class="nav-list"> <li> <a href="/" class="standard-link"> Home </a> </li><li> <a href="/pulse" class="standard-link"> Agentic Pulse </a> </li><li> <a href="/stack" class="standard-link"> Agentic Stack </a> </li><li> <a href="/hub" class="standard-link"> Agentic Hub </a> </li><li> <a href="/about" class="standard-link"> About </a> </li> <li><style>astro-island,astro-slot,astro-static-slot{display:contents}</style><script>(()=>{var e=async t=>{await(await t())()};(self.Astro||(self.Astro={})).load=e;window.dispatchEvent(new Event("astro:load"));})();</script><script>(()=>{var A=Object.defineProperty;var g=(i,o,a)=>o in i?A(i,o,{enumerable:!0,configurable:!0,writable:!0,value:a}):i[o]=a;var d=(i,o,a)=>g(i,typeof o!="symbol"?o+"":o,a);{let i={0:t=>m(t),1:t=>a(t),2:t=>new RegExp(t),3:t=>new Date(t),4:t=>new Map(a(t)),5:t=>new Set(a(t)),6:t=>BigInt(t),7:t=>new URL(t),8:t=>new Uint8Array(t),9:t=>new Uint16Array(t),10:t=>new Uint32Array(t),11:t=>1/0*t},o=t=>{let[l,e]=t;return l in i?i[l](e):void 0},a=t=>t.map(o),m=t=>typeof t!="object"||t===null?t:Object.fromEntries(Object.entries(t).map(([l,e])=>[l,o(e)]));class y extends HTMLElement{constructor(){super(...arguments);d(this,"Component");d(this,"hydrator");d(this,"hydrate",async()=>{var b;if(!this.hydrator||!this.isConnected)return;let e=(b=this.parentElement)==null?void 0:b.closest("astro-island[ssr]");if(e){e.addEventListener("astro:hydrate",this.hydrate,{once:!0});return}let c=this.querySelectorAll("astro-slot"),n={},h=this.querySelectorAll("template[data-astro-template]");for(let r of h){let s=r.closest(this.tagName);s!=null&&s.isSameNode(this)&&(n[r.getAttribute("data-astro-template")||"default"]=r.innerHTML,r.remove())}for(let r of c){let s=r.closest(this.tagName);s!=null&&s.isSameNode(this)&&(n[r.getAttribute("name")||"default"]=r.innerHTML)}let p;try{p=this.hasAttribute("props")?m(JSON.parse(this.getAttribute("props"))):{}}catch(r){let s=this.getAttribute("component-url")||"<unknown>",v=this.getAttribute("component-export");throw v&&(s+=` (export ${v})`),console.error(`[hydrate] Error parsing props for component ${s}`,this.getAttribute("props"),r),r}let u;await this.hydrator(this)(this.Component,p,n,{client:this.getAttribute("client")}),this.removeAttribute("ssr"),this.dispatchEvent(new CustomEvent("astro:hydrate"))});d(this,"unmount",()=>{this.isConnected||this.dispatchEvent(new CustomEvent("astro:unmount"))})}disconnectedCallback(){document.removeEventListener("astro:after-swap",this.unmount),document.addEventListener("astro:after-swap",this.unmount,{once:!0})}connectedCallback(){if(!this.hasAttribute("await-children")||document.readyState==="interactive"||document.readyState==="complete")this.childrenConnectedCallback();else{let e=()=>{document.removeEventListener("DOMContentLoaded",e),c.disconnect(),this.childrenConnectedCallback()},c=new MutationObserver(()=>{var n;((n=this.lastChild)==null?void 0:n.nodeType)===Node.COMMENT_NODE&&this.lastChild.nodeValue==="astro:end"&&(this.lastChild.remove(),e())});c.observe(this,{childList:!0}),document.addEventListener("DOMContentLoaded",e)}}async childrenConnectedCallback(){let e=this.getAttribute("before-hydration-url");e&&await import(e),this.start()}async start(){let e=JSON.parse(this.getAttribute("opts")),c=this.getAttribute("client");if(Astro[c]===void 0){window.addEventListener(`astro:${c}`,()=>this.start(),{once:!0});return}try{await Astro[c](async()=>{let n=this.getAttribute("renderer-url"),[h,{default:p}]=await Promise.all([import(this.getAttribute("component-url")),n?import(n):()=>()=>{}]),u=this.getAttribute("component-export")||"default";if(!u.includes("."))this.Component=h[u];else{this.Component=h;for(let f of u.split("."))this.Component=this.Component[f]}return this.hydrator=p,this.hydrate},e,this)}catch(n){console.error(`[astro-island] Error hydrating ${this.getAttribute("component-url")}`,n)}}attributeChangedCallback(){this.hydrate()}}d(y,"observedAttributes",["props"]),customElements.get("astro-island")||customElements.define("astro-island",y)}})();</script><astro-island uid="23TpQb" prefix="r1" component-url="/_astro/ProfileBadge.C0sqxJXU.js" component-export="default" renderer-url="/_astro/client.9unXo8s5.js" props="{}" ssr client="load" opts="{&quot;name&quot;:&quot;ProfileBadge&quot;,&quot;value&quot;:true}" await-children><div class="badge-skeleton"></div><!--astro:end--></astro-island></li> </ul> </nav> </div> </header> <div class="sticky top-16 z-40 w-full bg-zinc-950/80 backdrop-blur-md border-b border-zinc-800"> <div class="max-w-7xl mx-auto px-6 flex items-center justify-between h-14"> <div class="flex items-center gap-6"> <a href="/stack/brain" class="text-xs font-semibold uppercase tracking-wider transition-all text-zinc-400 hover:text-white"> Brain </a><a href="/stack/logic" class="text-xs font-semibold uppercase tracking-wider transition-all text-zinc-400 hover:text-white"> Logic </a><a href="/stack/memory" class="text-xs font-semibold uppercase tracking-wider transition-all text-zinc-400 hover:text-white"> Memory </a><a href="/stack/hands" class="text-xs font-semibold uppercase tracking-wider transition-all text-zinc-400 hover:text-white"> Hands </a><a href="/stack/guardrails" class="text-xs font-semibold uppercase tracking-wider transition-all text-zinc-400 hover:text-white"> Guardrails </a> </div> </div> </div> <aside class="w-64 fixed left-0 top-16 bottom-0 overflow-y-auto border-r border-zinc-800 bg-zinc-950/50 backdrop-blur-xl hidden lg:block z-30"> <nav class="p-6 space-y-8"> <div> <h3 class="text-[10px] font-bold text-zinc-500 uppercase tracking-[0.2em] mb-4">The Framework</h3> <ul class="space-y-1"> <li> <a href="/stack/brain" class="group flex items-center gap-3 px-3 py-2 rounded-md text-sm transition-all duration-200 bg-blue-600/10 text-blue-400 border border-blue-500/20 shadow-[0_0_15px_rgba(59,130,246,0.1)]"> <span class="text-[10px] font-mono text-blue-400">
01 </span> Reasoning Brain </a> </li><li> <a href="/stack/guardrails" class="group flex items-center gap-3 px-3 py-2 rounded-md text-sm transition-all duration-200 text-zinc-400 hover:bg-zinc-900 hover:text-zinc-100 border border-transparent"> <span class="text-[10px] font-mono text-zinc-600">
02 </span> Orchestration </a> </li><li> <a href="/stack/hands" class="group flex items-center gap-3 px-3 py-2 rounded-md text-sm transition-all duration-200 text-zinc-400 hover:bg-zinc-900 hover:text-zinc-100 border border-transparent"> <span class="text-[10px] font-mono text-zinc-600">
02 </span> Orchestration </a> </li><li> <a href="/stack/logic" class="group flex items-center gap-3 px-3 py-2 rounded-md text-sm transition-all duration-200 text-zinc-400 hover:bg-zinc-900 hover:text-zinc-100 border border-transparent"> <span class="text-[10px] font-mono text-zinc-600">
02 </span> Orchestration </a> </li><li> <a href="/stack/memory" class="group flex items-center gap-3 px-3 py-2 rounded-md text-sm transition-all duration-200 text-zinc-400 hover:bg-zinc-900 hover:text-zinc-100 border border-transparent"> <span class="text-[10px] font-mono text-zinc-600">
02 </span> Orchestration </a> </li> </ul> </div> </nav> </aside> <main class="lg:ml-64 min-h-screen bg-black"> <div class="max-w-7xl mx-auto py-12 px-6 lg:px-12 grid grid-cols-1 xl:grid-cols-4 gap-12"></div> <section class="max-w-7xl mx-auto px-6 lg:px-12 pb-24 w-full"> <div class="flex items-center gap-4 mb-10"> <h2 class="text-[10px] font-black text-zinc-500 uppercase tracking-[0.4em]">
Implementation Deep Dives
</h2> <div class="h-[1px] flex-grow bg-zinc-800"></div> </div> <div class="flex flex-col gap-6 w-full"> <div class="resource-card group relative w-full bg-zinc-900/20 border border-zinc-800/80 rounded-[3rem] overflow-hidden transition-all duration-500 cursor-pointer" data-expanded="false"> <div class="flex items-center justify-between p-8 md:p-10 w-full"> <div class="flex items-center gap-8"> <div class="shrink-0 px-4 py-1.5 rounded-full bg-blue-500/10 border border-blue-500/20 text-blue-400 font-mono text-[10px] font-bold uppercase tracking-widest"> Module </div> <h3 class="text-xl md:text-2xl font-bold text-white group-hover:text-blue-400"> The Great Regression: Why AI Agents Look Like 1980s Computing </h3> </div> <div class="icon-circle w-12 h-12 rounded-full bg-zinc-800 flex items-center justify-center transition-all duration-500 group-hover:bg-blue-600"> <svg xmlns="http://www.w3.org/2000/svg" class="w-6 h-6 text-white chevron-icon transition-transform duration-500" fill="none" viewBox="0 0 24 24" stroke="currentColor"> <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" d="M19 9l-7 7-7-7"></path> </svg> </div> </div> <div class="expand-wrapper overflow-hidden transition-all duration-700 ease-in-out"> <div class="px-10 md:px-20 pb-12 pt-4 border-t border-zinc-800/50"> <p class="text-zinc-300 text-lg leading-relaxed mb-8"> The article draws parallels between the current state of AI agent development and the computing paradigms of the 1980s. It suggests that despite the advanced capabilities of modern AI, the design and functionality of AI agents often resemble the early computing models, characterized by limited autonomy and a reliance on predefined instructions. This observation highlights a regression in the evolution of AI agents, where the potential for more sophisticated, self-directed systems remains underexplored.

This comparison is significant for the AI ecosystem as it underscores a potential stagnation in the innovation of AI agents. While the broader field of AI has seen remarkable advancements, the development of truly autonomous agents has not kept pace. This stagnation could impact the strategic direction of AI research and development, as businesses and researchers may need to reassess their approaches to creating more dynamic and adaptable AI systems. For AI entrepreneurs and developers, this insight could guide investment and development priorities, emphasizing the need for breakthroughs in agent autonomy and decision-making capabilities.

Experts in the field may view this as a call to action to push beyond current limitations and explore new paradigms in AI agent development. The article suggests that the future trajectory of AI agents should focus on enhancing their ability to operate independently and adaptively in complex environments. This shift could redefine the landscape of AI applications, offering more robust and versatile solutions across industries. However, achieving this will require overcoming significant technical challenges and fostering interdisciplinary collaboration to integrate insights from cognitive science, robotics, and machine learning. </p> <a href="https://medium.com/@dinesh707/the-great-regression-why-ai-agents-look-like-1980s-computing-d5e7ec1ac4c1?source=rss------ai_agents-5" target="_blank" class="inline-flex items-center gap-3 px-8 py-3.5 rounded-full bg-blue-600 text-white font-bold" onclick="event.stopPropagation();">
Read More →
</a> </div> </div> </div><div class="resource-card group relative w-full bg-zinc-900/20 border border-zinc-800/80 rounded-[3rem] overflow-hidden transition-all duration-500 cursor-pointer" data-expanded="false"> <div class="flex items-center justify-between p-8 md:p-10 w-full"> <div class="flex items-center gap-8"> <div class="shrink-0 px-4 py-1.5 rounded-full bg-blue-500/10 border border-blue-500/20 text-blue-400 font-mono text-[10px] font-bold uppercase tracking-widest"> Module </div> <h3 class="text-xl md:text-2xl font-bold text-white group-hover:text-blue-400"> Anthropic launches Cowork, a Claude Desktop agent that works in your files — no coding required </h3> </div> <div class="icon-circle w-12 h-12 rounded-full bg-zinc-800 flex items-center justify-center transition-all duration-500 group-hover:bg-blue-600"> <svg xmlns="http://www.w3.org/2000/svg" class="w-6 h-6 text-white chevron-icon transition-transform duration-500" fill="none" viewBox="0 0 24 24" stroke="currentColor"> <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" d="M19 9l-7 7-7-7"></path> </svg> </div> </div> <div class="expand-wrapper overflow-hidden transition-all duration-700 ease-in-out"> <div class="px-10 md:px-20 pb-12 pt-4 border-t border-zinc-800/50"> <p class="text-zinc-300 text-lg leading-relaxed mb-8"> &lt;p&gt;&lt;a href=&quot;https://www.anthropic.com/&quot;&gt;Anthropic&lt;/a&gt; released &lt;a href=&quot;https://claude.com/blog/cowork-research-preview&quot;&gt;Cowork&lt;/a&gt; on Monday, a new AI agent capability that extends the power of its wildly successful &lt;a href=&quot;https://claude.com/product/claude-code&quot;&gt;Claude Code&lt;/a&gt; tool to non-technical users — and according to company insiders, the team built the entire feature in approximately a week and a half, largely using Claude Code itself.&lt;/p&gt;&lt;p&gt;The launch marks a major inflection point in the race to deliver practical AI agents to mainstream users, positioning Anthropic to compete not just with &lt;a href=&quot;https://openai.com/&quot;&gt;OpenAI&lt;/a&gt; and &lt;a href=&quot;https://gemini.google.com/app&quot;&gt;Google&lt;/a&gt; in conversational AI, but with &lt;a href=&quot;https://copilot.microsoft.com/&quot;&gt;Microsoft&amp;#x27;s Copilot&lt;/a&gt; in the burgeoning market for AI-powered productivity tools.&lt;/p&gt;&lt;p&gt;&amp;quot;Cowork lets you complete non-technical tasks much like how developers use Claude Code,&amp;quot; the &lt;a href=&quot;https://x.com/claudeai/status/2010805682434666759?s=20&quot;&gt;company announced&lt;/a&gt; via its official Claude account on X. The feature arrives as a research preview available exclusively to &lt;a href=&quot;https://support.claude.com/en/articles/11014257-about-claude-s-max-plan-usage&quot;&gt;Claude Max subscribers&lt;/a&gt; — Anthropic&amp;#x27;s power-user tier priced between $100 and $200 per month — through the macOS desktop application.&lt;/p&gt;&lt;p&gt;For the past year, the industry narrative has focused on large language models that can write poetry or debug code. With &lt;a href=&quot;https://claude.com/blog/cowork-research-preview&quot;&gt;Cowork&lt;/a&gt;, Anthropic is betting that the real enterprise value lies in an AI that can open a folder, read a messy pile of receipts, and generate a structured expense report without human hand-holding.&lt;/p&gt;&lt;div&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;How developers using a coding tool for vacation research inspired Anthropic&amp;#x27;s latest product&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The genesis of &lt;a href=&quot;https://claude.com/blog/cowork-research-preview&quot;&gt;Cowork&lt;/a&gt; lies in Anthropic&amp;#x27;s recent success with the developer community. In late 2024, the company released &lt;a href=&quot;https://www.anthropic.com/news/claude-3-7-sonnet&quot;&gt;Claude Code&lt;/a&gt;, a terminal-based tool that allowed software engineers to automate rote programming tasks. The tool was a hit, but Anthropic noticed a peculiar trend: users were forcing the coding tool to perform non-coding labor.&lt;/p&gt;&lt;p&gt;According to &lt;a href=&quot;https://x.com/bcherny/status/2010809450844831752&quot;&gt;Boris Cherny&lt;/a&gt;, an engineer at Anthropic, the company observed users deploying the developer tool for an unexpectedly diverse array of tasks.&lt;/p&gt;&lt;div&gt;&lt;/div&gt;&lt;p&gt;&amp;quot;Since we launched Claude Code, we saw people using it for all sorts of non-coding work: doing vacation research, building slide decks, cleaning up your email, cancelling subscriptions, recovering wedding photos from a hard drive, monitoring plant growth, controlling your oven,&amp;quot; Cherny wrote on X. &amp;quot;These use cases are diverse and surprising — the reason is that the underlying Claude Agent is the best agent, and Opus 4.5 is the best model.&amp;quot;&lt;/p&gt;&lt;p&gt;Recognizing this shadow usage, Anthropic effectively stripped the command-line complexity from their developer tool to create a consumer-friendly interface. In its blog post announcing the feature, &lt;a href=&quot;https://claude.com/blog/cowork-research-preview&quot;&gt;Anthropic explained&lt;/a&gt; that developers &amp;quot;quickly began using it for almost everything else,&amp;quot; which &amp;quot;prompted us to build Cowork: a simpler way for anyone — not just developers — to work with Claude in the very same way.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Inside the folder-based architecture that lets Claude read, edit, and create files on your computer&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Unlike a standard chat interface where a user pastes text for analysis, &lt;a href=&quot;https://claude.com/blog/cowork-research-preview&quot;&gt;Cowork&lt;/a&gt; requires a different level of trust and access. Users designate a specific folder on their local machine that Claude can access. Within that sandbox, the AI agent can read existing files, modify them, or create entirely new ones.&lt;/p&gt;&lt;p&gt;Anthropic offers several illustrative examples: reorganizing a cluttered downloads folder by sorting and intelligently renaming each file, generating a spreadsheet of expenses from a collection of receipt screenshots, or drafting a report from scattered notes across multiple documents.&lt;/p&gt;&lt;p&gt;&amp;quot;In Cowork, you give Claude access to a folder on your computer. Claude can then read, edit, or create files in that folder,&amp;quot; &lt;a href=&quot;https://x.com/claudeai/status/2010805685530038351&quot;&gt;the company explained&lt;/a&gt; on X. &amp;quot;Try it to create a spreadsheet from a pile of screenshots, or produce a first draft from scattered notes.&amp;quot;&lt;/p&gt;&lt;div&gt;&lt;/div&gt;&lt;p&gt;The architecture relies on what is known as an &amp;quot;agentic loop.&amp;quot; When a user assigns a task, the AI does not merely generate a text response. Instead, it formulates a plan, executes steps in parallel, checks its own work, and asks for clarification if it hits a roadblock. Users can queue multiple tasks and let Claude process them simultaneously — a workflow Anthropic describes as feeling &amp;quot;much less like a back-and-forth and much more like leaving messages for a coworker.&amp;quot;&lt;/p&gt;&lt;p&gt;The system is built on Anthropic&amp;#x27;s &lt;a href=&quot;https://www.anthropic.com/engineering/building-agents-with-the-claude-agent-sdk&quot;&gt;Claude Agent SDK&lt;/a&gt;, meaning it shares the same underlying architecture as Claude Code. Anthropic notes that Cowork &amp;quot;can take on many of the same tasks that Claude Code can handle, but in a more approachable form for non-coding tasks.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The recursive loop where AI builds AI: Claude Code reportedly wrote much of Claude Cowork&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Perhaps the most remarkable detail surrounding Cowork&amp;#x27;s launch is the speed at which the tool was reportedly built — highlighting a recursive feedback loop where AI tools are being used to build better AI tools.&lt;/p&gt;&lt;p&gt;During a livestream hosted by Dan Shipper, Felix Rieseberg, an Anthropic employee, confirmed that &lt;a href=&quot;https://x.com/blakeir/status/2010837251505205656&quot;&gt;t&lt;/a&gt;he team &lt;a href=&quot;https://x.com/blakeir/status/2010837251505205656&quot;&gt;built Cowork in approximately a week and a half&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Alex Volkov, who covers AI developments, expressed surprise at the timeline: &amp;quot;Holy shit Anthropic built &amp;#x27;Cowork&amp;#x27; in the last... week and a half?!&amp;quot;&lt;/p&gt;&lt;div&gt;&lt;/div&gt;&lt;p&gt;This prompted immediate speculation about how much of Cowork was itself built by Claude Code. &lt;a href=&quot;https://x.com/_simonsmith&quot;&gt;Simon Smith&lt;/a&gt;, EVP of Generative AI at Klick Health, put it bluntly on X: &amp;quot;Claude Code wrote all of Claude Cowork. Can we all agree that we&amp;#x27;re in at least somewhat of a recursive improvement loop here?&amp;quot;&lt;/p&gt;&lt;p&gt;The implication is profound: Anthropic&amp;#x27;s AI coding agent may have substantially contributed to building its own non-technical sibling product. If true, this is one of the most visible examples yet of AI systems being used to accelerate their own development and expansion — a strategy that could widen the gap between AI labs that successfully deploy their own agents internally and those that do not.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Connectors, browser automation, and skills extend Cowork&amp;#x27;s reach beyond the local file system&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Cowork doesn&amp;#x27;t operate in isolation. The feature integrates with Anthropic&amp;#x27;s existing ecosystem of connectors — tools that link &lt;a href=&quot;https://claude.ai/login?returnTo=%2Fnew%3F&quot;&gt;Claude&lt;/a&gt; to external information sources and services such as &lt;a href=&quot;https://asana.com/&quot;&gt;Asana&lt;/a&gt;, &lt;a href=&quot;https://www.notion.com/&quot;&gt;Notion&lt;/a&gt;, &lt;a href=&quot;https://www.paypal.com/us/home&quot;&gt;PayPal&lt;/a&gt;, and other supported partners. Users who have configured these connections in the standard Claude interface can leverage them within Cowork sessions.&lt;/p&gt;&lt;p&gt;Additionally, Cowork can pair with &lt;a href=&quot;https://code.claude.com/docs/en/chrome&quot;&gt;Claude in Chrome&lt;/a&gt;, Anthropic&amp;#x27;s browser extension, to execute tasks requiring web access. This combination allows the agent to navigate websites, click buttons, fill forms, and extract information from the internet — all while operating from the desktop application.&lt;/p&gt;&lt;p&gt;&amp;quot;Cowork includes a number of novel UX and safety features that we think make the product really special,&amp;quot; &lt;a href=&quot;https://x.com/bcherny/status/2010809450844831752&quot;&gt;Cherny explained&lt;/a&gt;, highlighting &amp;quot;a built-in VM [virtual machine] for isolation, out of the box support for browser automation, support for all your claude.ai data connectors, asking you for clarification when it&amp;#x27;s unsure.&amp;quot;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.anthropic.com/&quot;&gt;Anthropic&lt;/a&gt; has also introduced an initial set of &amp;quot;skills&amp;quot; specifically designed for Cowork that enhance Claude&amp;#x27;s ability to create documents, presentations, and other files. These build on the &lt;a href=&quot;https://www.anthropic.com/engineering/equipping-agents-for-the-real-world-with-agent-skills&quot;&gt;Skills for Claude&lt;/a&gt; framework the company announced in October, which provides specialized instruction sets Claude can load for particular types of tasks.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why Anthropic is warning users that its own AI agent could delete their files&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The transition from a chatbot that suggests edits to an agent that makes edits introduces significant risk. An AI that can organize files can, theoretically, delete them.&lt;/p&gt;&lt;p&gt;In a notable display of transparency, Anthropic devoted considerable space in its announcement to &lt;a href=&quot;https://claude.com/blog/cowork-research-preview&quot;&gt;warning users about Cowork&amp;#x27;s potential dangers&lt;/a&gt; — an unusual approach for a product launch.&lt;/p&gt;&lt;p&gt;The company explicitly acknowledges that Claude &amp;quot;can take potentially destructive actions (such as deleting local files) if it&amp;#x27;s instructed to.&amp;quot; Because Claude might occasionally misinterpret instructions, Anthropic urges users to provide &amp;quot;very clear guidance&amp;quot; about sensitive operations.&lt;/p&gt;&lt;p&gt;More concerning is the risk of prompt injection attacks — a technique where malicious actors embed hidden instructions in content Claude might encounter online, potentially causing the agent to bypass safeguards or take harmful actions.&lt;/p&gt;&lt;p&gt;&amp;quot;We&amp;#x27;ve built sophisticated defenses against prompt injections,&amp;quot; Anthropic wrote, &amp;quot;but agent safety — that is, the task of securing Claude&amp;#x27;s real-world actions — is still an active area of development in the industry.&amp;quot;&lt;/p&gt;&lt;p&gt;The company characterized these risks as inherent to the current state of AI agent technology rather than unique to Cowork. &amp;quot;These risks aren&amp;#x27;t new with Cowork, but it might be the first time you&amp;#x27;re using a more advanced tool that moves beyond a simple conversation,&amp;quot; the announcement notes.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Anthropic&amp;#x27;s desktop agent strategy sets up a direct challenge to Microsoft Copilot&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The launch of &lt;a href=&quot;https://claude.com/blog/cowork-research-preview&quot;&gt;Cowork&lt;/a&gt; places Anthropic in direct competition with &lt;a href=&quot;https://www.microsoft.com/en-us/&quot;&gt;Microsoft&lt;/a&gt;, which has spent years attempting to integrate its &lt;a href=&quot;https://copilot.microsoft.com/&quot;&gt;Copilot AI&lt;/a&gt; into the fabric of the Windows operating system with mixed adoption results.&lt;/p&gt;&lt;p&gt;However, Anthropic&amp;#x27;s approach differs in its isolation. By confining the agent to specific folders and requiring explicit connectors, they are attempting to strike a balance between the utility of an OS-level agent and the security of a sandboxed application.&lt;/p&gt;&lt;p&gt;What distinguishes Anthropic&amp;#x27;s approach is its bottom-up evolution. Rather than designing an AI assistant and retrofitting agent capabilities, Anthropic built a powerful coding agent first — &lt;a href=&quot;https://code.claude.com/docs/en/overview&quot;&gt;Claude Code&lt;/a&gt; — and is now abstracting its capabilities for broader audiences. This technical lineage may give Cowork more robust agentic behavior from the start.&lt;/p&gt;&lt;p&gt;Claude Code has generated significant enthusiasm among developers since its initial launch as &lt;a href=&quot;https://www.anthropic.com/news/claude-3-7-sonnet&quot;&gt;a command-line tool in late 2024&lt;/a&gt;. The company expanded access with a &lt;a href=&quot;https://arstechnica.com/ai/2025/10/claude-code-gets-a-web-version-but-its-the-new-sandboxing-that-really-matters/&quot;&gt;web interface&lt;/a&gt; in October 2025, followed by a &lt;a href=&quot;https://venturebeat.com/ai/anthropics-claude-code-can-now-read-your-slack-messages-and-write-code-for&quot;&gt;Slack integration&lt;/a&gt; in December. Cowork is the next logical step: bringing the same agentic architecture to users who may never touch a terminal.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Who can access Cowork now, and what&amp;#x27;s coming next for Windows and other platforms&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;For now, Cowork remains exclusive to &lt;a href=&quot;https://support.claude.com/en/articles/11014257-about-claude-s-max-plan-usage&quot;&gt;Claude Max subscribers&lt;/a&gt; using the macOS desktop application. Users on other subscription tiers — Free, Pro, Team, or Enterprise — can join a waitlist for future access.&lt;/p&gt;&lt;p&gt;Anthropic has signaled clear intentions to expand the feature&amp;#x27;s reach. The blog post explicitly mentions plans to add cross-device sync and bring Cowork to Windows as the company learns from the research preview.&lt;/p&gt;&lt;p&gt;Cherny set expectations appropriately, describing the product as &amp;quot;early and raw, similar to what Claude Code felt like when it first launched.&amp;quot;&lt;/p&gt;&lt;p&gt;To access &lt;a href=&quot;https://claude.com/blog/cowork-research-preview&quot;&gt;Cowork&lt;/a&gt;, Max subscribers can download or update the Claude macOS app and click on &amp;quot;Cowork&amp;quot; in the sidebar.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The real question facing enterprise AI adoption&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;For technical decision-makers, the implications of Cowork extend beyond any single product launch. The bottleneck for AI adoption is shifting — no longer is model intelligence the limiting factor, but rather workflow integration and user trust.&lt;/p&gt;&lt;p&gt;Anthropic&amp;#x27;s goal, as the company puts it, is to make working with Claude feel less like operating a tool and more like delegating to a colleague. Whether mainstream users are ready to hand over folder access to an AI that might misinterpret their instructions remains an open question.&lt;/p&gt;&lt;p&gt;But the speed of Cowork&amp;#x27;s development — a major feature built in ten days, possibly by the company&amp;#x27;s own AI — previews a future where the capabilities of these systems compound faster than organizations can evaluate them. &lt;/p&gt;&lt;p&gt;The chatbot has learned to use a file manager. What it learns to use next is anyone&amp;#x27;s guess.&lt;/p&gt; </p> <a href="https://venturebeat.com/technology/anthropic-launches-cowork-a-claude-desktop-agent-that-works-in-your-files-no" target="_blank" class="inline-flex items-center gap-3 px-8 py-3.5 rounded-full bg-blue-600 text-white font-bold" onclick="event.stopPropagation();">
Read More →
</a> </div> </div> </div><div class="resource-card group relative w-full bg-zinc-900/20 border border-zinc-800/80 rounded-[3rem] overflow-hidden transition-all duration-500 cursor-pointer" data-expanded="false"> <div class="flex items-center justify-between p-8 md:p-10 w-full"> <div class="flex items-center gap-8"> <div class="shrink-0 px-4 py-1.5 rounded-full bg-blue-500/10 border border-blue-500/20 text-blue-400 font-mono text-[10px] font-bold uppercase tracking-widest"> Module </div> <h3 class="text-xl md:text-2xl font-bold text-white group-hover:text-blue-400"> Salesforce rolls out new Slackbot AI agent as it battles Microsoft and Google in workplace AI </h3> </div> <div class="icon-circle w-12 h-12 rounded-full bg-zinc-800 flex items-center justify-center transition-all duration-500 group-hover:bg-blue-600"> <svg xmlns="http://www.w3.org/2000/svg" class="w-6 h-6 text-white chevron-icon transition-transform duration-500" fill="none" viewBox="0 0 24 24" stroke="currentColor"> <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" d="M19 9l-7 7-7-7"></path> </svg> </div> </div> <div class="expand-wrapper overflow-hidden transition-all duration-700 ease-in-out"> <div class="px-10 md:px-20 pb-12 pt-4 border-t border-zinc-800/50"> <p class="text-zinc-300 text-lg leading-relaxed mb-8"> &lt;p&gt;&lt;a href=&quot;https://www.salesforce.com/&quot;&gt;Salesforce&lt;/a&gt; on Tuesday launched an entirely rebuilt version of &lt;a href=&quot;https://slack.com/help/articles/202026038-An-introduction-to-Slackbot&quot;&gt;Slackbot&lt;/a&gt;, the company&amp;#x27;s workplace assistant, transforming it from a simple notification tool into what executives describe as a fully powered AI agent capable of searching enterprise data, drafting documents, and taking action on behalf of employees.&lt;/p&gt;&lt;p&gt;The new Slackbot, now generally available to &lt;a href=&quot;https://slack.com/pricing/businessplus&quot;&gt;Business+&lt;/a&gt; and &lt;a href=&quot;https://slack.com/enterprise&quot;&gt;Enterprise+&lt;/a&gt; customers, is Salesforce&amp;#x27;s most aggressive move yet to position Slack at the center of the emerging &amp;quot;agentic AI&amp;quot; movement — where software agents work alongside humans to complete complex tasks. The launch comes as Salesforce attempts to convince investors that artificial intelligence will bolster its products rather than render them obsolete.&lt;/p&gt;&lt;p&gt;&amp;quot;Slackbot isn&amp;#x27;t just another copilot or AI assistant,&amp;quot; said &lt;a href=&quot;https://www.salesforce.com/company/parker-harris-bio/&quot;&gt;Parker Harris&lt;/a&gt;, Salesforce co-founder and Slack&amp;#x27;s chief technology officer, in an exclusive interview with Salesforce. &amp;quot;It&amp;#x27;s the front door to the agentic enterprise, powered by Salesforce.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;From tricycle to Porsche: Salesforce rebuilt Slackbot from the ground up&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Harris was blunt about what distinguishes the new Slackbot from its predecessor: &amp;quot;The old Slackbot was, you know, a little tricycle, and the new Slackbot is like, you know, a Porsche.&amp;quot;&lt;/p&gt;&lt;p&gt;The original Slackbot, which has existed since Slack&amp;#x27;s early days, performed basic algorithmic tasks — reminding users to add colleagues to documents, suggesting channel archives, and delivering simple notifications. The new version runs on an entirely different architecture built around a large language model and sophisticated search capabilities that can access Salesforce records, Google Drive files, calendar data, and years of Slack conversations.&lt;/p&gt;&lt;p&gt;&amp;quot;It&amp;#x27;s two different things,&amp;quot; Harris explained. &amp;quot;The old Slackbot was algorithmic and fairly simple. The new Slackbot is brand new — it&amp;#x27;s based around an LLM and a very robust search engine, and connections to third-party search engines, third-party enterprise data.&amp;quot;&lt;/p&gt;&lt;p&gt;Salesforce chose to retain the Slackbot brand despite the fundamental technical overhaul. &amp;quot;People know what Slackbot is, and so we wanted to carry that forward,&amp;quot; Harris said.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why Anthropic&amp;#x27;s Claude powers the new Slackbot — and which AI models could come next&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The new Slackbot runs on &lt;a href=&quot;https://claude.ai/&quot;&gt;Claude&lt;/a&gt;, Anthropic&amp;#x27;s large language model, a choice driven partly by compliance requirements. Slack&amp;#x27;s commercial service operates under &lt;a href=&quot;https://www.fedramp.gov/archive/2017-11-16-understanding-baselines-and-impact-levels/&quot;&gt;FedRAMP Moderate certification&lt;/a&gt; to serve U.S. federal government customers, and Harris said Anthropic was &amp;quot;the only provider that could give us a compliant LLM&amp;quot; when Slack began building the new system.&lt;/p&gt;&lt;p&gt;But that exclusivity won&amp;#x27;t last. &amp;quot;We are, this year, going to support additional providers,&amp;quot; Harris said. &amp;quot;We have a great relationship with Google. Gemini is incredible — performance is great, cost is great. So we&amp;#x27;re going to use Gemini for some things.&amp;quot; He added that OpenAI remains a possibility as well.&lt;/p&gt;&lt;p&gt;Harris echoed Salesforce CEO Marc Benioff&amp;#x27;s view that large language models are becoming commoditized: &amp;quot;You&amp;#x27;ve heard Marc talk about LLMs are commodities, that they&amp;#x27;re democratized. I call them CPUs.&amp;quot;&lt;/p&gt;&lt;p&gt;On the sensitive question of training data, Harris was unequivocal: Salesforce does not train any models on customer data. &amp;quot;Models don&amp;#x27;t have any sort of security,&amp;quot; he explained. &amp;quot;If we trained it on some confidential conversation that you and I have, I don&amp;#x27;t want Carolyn to know — if I train it into the LLM, there is no way for me to say you get to see the answer, but Carolyn doesn&amp;#x27;t.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Inside Salesforce&amp;#x27;s internal experiment: 80,000 employees tested Slackbot with striking results&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Salesforce has been &lt;a href=&quot;https://www.theverge.com/news/797890/slack-slackbot-ai-assistant-upgrade&quot;&gt;testing the new Slackbot internally for months&lt;/a&gt;, rolling it out to all 80,000 employees. According to Ryan Gavin, Slack&amp;#x27;s chief marketing officer, the results have been striking: &amp;quot;It&amp;#x27;s the fastest adopted product in Salesforce history.&amp;quot;&lt;/p&gt;&lt;p&gt;Internal data shows that two-thirds of Salesforce employees have tried the new Slackbot, with 80% of those users continuing to use it regularly. Internal satisfaction rates reached 96% — the highest for any AI feature Slack has shipped. Employees report saving between two and 20 hours per week.&lt;/p&gt;&lt;p&gt;The adoption happened largely organically. &amp;quot;I think it was about five days, and a Canvas was developed by our employees called &amp;#x27;The Most Stealable Slackbot Prompts,&amp;#x27;&amp;quot; Gavin said. &amp;quot;People just started adding to it organically. I think it&amp;#x27;s up to 250-plus prompts that are in this Canvas right now.&amp;quot;&lt;/p&gt;&lt;p&gt;Kate Crotty, a principal UX researcher at Salesforce, found that 73% of internal adoption was driven by social sharing rather than top-down mandates. &amp;quot;Everybody is there to help each other learn and communicate hacks,&amp;quot; she said.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How Slackbot transforms scattered enterprise data into executive-ready insights&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;During a product demonstration, Amy Bauer, Slack&amp;#x27;s product experience designer, showed how Slackbot can synthesize information across multiple sources. In one example, she asked Slackbot to analyze customer feedback from a pilot program, upload an image of a usage dashboard, and have Slackbot correlate the qualitative and quantitative data.&lt;/p&gt;&lt;p&gt;&amp;quot;This is where Slackbot really earns its keep for me,&amp;quot; Bauer explained. &amp;quot;What it&amp;#x27;s doing is not just simply reading the image — it&amp;#x27;s actually looking at the image and comparing it to the insight it just generated for me.&amp;quot;&lt;/p&gt;&lt;p&gt;Slackbot can then query Salesforce to find enterprise accounts with open deals that might be good candidates for early access, creating what Bauer called &amp;quot;a really great justification and plan to move forward.&amp;quot; Finally, it can synthesize all that information into a Canvas — Slack&amp;#x27;s collaborative document format — and find calendar availability among stakeholders to schedule a review meeting.&lt;/p&gt;&lt;p&gt;&amp;quot;Up until this point, we have been working in a one-to-one capacity with Slackbot,&amp;quot; Bauer said. &amp;quot;But one of the benefits that I can do now is take this insight and have it generate this into a Canvas, a shared workspace where I can iterate on it, refine it with Slackbot, or share it out with my team.&amp;quot;&lt;/p&gt;&lt;p&gt;Rob Seaman, Slack&amp;#x27;s chief product officer, said the Canvas creation demonstrates where the product is heading: &amp;quot;This is making a tool call internally to Slack Canvas to actually write, effectively, a shared document. But it signals where we&amp;#x27;re going with Slackbot — we&amp;#x27;re eventually going to be adding in additional third-party tool calls.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;MrBeast&amp;#x27;s company became a Slackbot guinea pig—and employees say they&amp;#x27;re saving 90 minutes a day&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Among Salesforce&amp;#x27;s pilot customers is &lt;a href=&quot;https://www.thecashmerefund.com/portfolio-company/beast-industries&quot;&gt;Beast Industries&lt;/a&gt;, the parent company of YouTube star MrBeast. Luis Madrigal, the company&amp;#x27;s chief information officer, joined the launch announcement to describe his experience.&lt;/p&gt;&lt;p&gt;&amp;quot;As somebody who has rolled out enterprise technologies for over two decades now, this was practically one of the easiest,&amp;quot; Madrigal said. &amp;quot;The plumbing is there. Slack as an implementation, Enterprise Tools — being able to turn on the Slackbot and the Slack AI functionality was as simple as having my team go in, review, do a quick security review.&amp;quot;&lt;/p&gt;&lt;p&gt;Madrigal said his security team signed off &amp;quot;rather quickly&amp;quot; — unusual for enterprise AI deployments — because Slackbot accesses only the information each individual user already has permission to view. &amp;quot;Given all the guardrails you guys have put into place for Slackbot to be unique and customized to only the information that each individual user has, only the conversations and the Slack rooms and Slack channels that they&amp;#x27;re part of—that made my security team sign off rather quickly.&amp;quot;&lt;/p&gt;&lt;p&gt;One Beast Industries employee, Sinan, the head of Beast Games marketing, reported saving &amp;quot;at bare minimum, 90 minutes a day.&amp;quot; Another employee, Spencer, a creative supervisor, described it as &amp;quot;an assistant who&amp;#x27;s paying attention when I&amp;#x27;m not.&amp;quot;&lt;/p&gt;&lt;p&gt;Other pilot customers include Slalom, reMarkable, Xero, Mercari, and Engine. Mollie Bodensteiner, SVP of Operations at Engine, called Slackbot &amp;quot;an absolute &amp;#x27;chaos tamer&amp;#x27; for our team,&amp;quot; estimating it saves her about 30 minutes daily &amp;quot;just by eliminating context switching.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Slackbot vs. Microsoft Copilot vs. Google Gemini: The fight for enterprise AI dominance&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The launch puts Salesforce in direct competition with &lt;a href=&quot;https://copilot.microsoft.com/&quot;&gt;Microsoft&amp;#x27;s Copilot&lt;/a&gt;, which is integrated into Teams and the broader Microsoft 365 suite, as well as Google&amp;#x27;s Gemini integrations across Workspace. When asked what distinguishes Slackbot from these alternatives, Seaman pointed to context and convenience.&lt;/p&gt;&lt;p&gt;&amp;quot;The thing that makes it most powerful for our customers and users is the proximity — it&amp;#x27;s just right there in your Slack,&amp;quot; Seaman said. &amp;quot;There&amp;#x27;s a tremendous convenience affordance that&amp;#x27;s naturally built into it.&amp;quot;&lt;/p&gt;&lt;p&gt;The deeper advantage, executives argue, is that Slackbot already understands users&amp;#x27; work without requiring setup or training. &amp;quot;Most AI tools sound the same no matter who is using them,&amp;quot; the company&amp;#x27;s announcement stated. &amp;quot;They lack context, miss nuance, and force you to jump between tools to get anything done.&amp;quot;&lt;/p&gt;&lt;p&gt;Harris put it more directly: &amp;quot;If you&amp;#x27;ve ever had that magic experience with AI — I think ChatGPT is a great example, it&amp;#x27;s a great experience from a consumer perspective — Slackbot is really what we&amp;#x27;re doing in the enterprise, to be this employee super agent that is loved, just like people love using Slack.&amp;quot;&lt;/p&gt;&lt;p&gt;Amy Bauer emphasized the frictionless nature of the experience. &amp;quot;Slackbot is inherently grounded in the context, in the data that you have in Slack,&amp;quot; she said. &amp;quot;So as you continue working in Slack, Slackbot gets better because it&amp;#x27;s grounded in the work that you&amp;#x27;re doing there. There is no setup. There is no configuration for those end users.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Salesforce&amp;#x27;s ambitious plan to make Slackbot the one &amp;#x27;super agent&amp;#x27; that controls all the others&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Salesforce positions Slackbot as what Harris calls a &amp;quot;super agent&amp;quot; — a central hub that can eventually coordinate with other AI agents across an organization.&lt;/p&gt;&lt;p&gt;&amp;quot;Every corporation is going to have an employee super agent,&amp;quot; Harris said. &amp;quot;Slackbot is essentially taking the magic of what Slack does. We think that Slackbot, and we&amp;#x27;re really excited about it, is going to be that.&amp;quot;&lt;/p&gt;&lt;p&gt;The vision extends to third-party agents already launching in Slack. Last month, Anthropic released a preview of Claude Code for Slack, allowing developers to interact with Claude&amp;#x27;s coding capabilities directly in chat threads. OpenAI, Google, Vercel, and others have also built agents for the platform.&lt;/p&gt;&lt;p&gt;&amp;quot;Most of the net-new apps that are being deployed to Slack are agents,&amp;quot; Seaman noted during the press conference. &amp;quot;This is proof of the promise of humans and agents coexisting and working together in Slack to solve problems.&amp;quot;&lt;/p&gt;&lt;p&gt;Harris described a future where Slackbot becomes an &lt;a href=&quot;https://modelcontextprotocol.io/docs/learn/client-concepts&quot;&gt;MCP (Model Context Protocol) client&lt;/a&gt;, able to leverage tools from across the software ecosystem — similar to how the developer tool Cursor works. &amp;quot;Slack can be an MCP client, and Slackbot will be the hub of that, leveraging all these tools out in the world, some of which will be these amazing agents,&amp;quot; he said.&lt;/p&gt;&lt;p&gt;But Harris also cautioned against over-promising on multi-agent coordination. &amp;quot;I still think we&amp;#x27;re in the single agent world,&amp;quot; he said. &amp;quot;FY26 is going to be the year where we started to see more coordination. But we&amp;#x27;re going to do it with customer success in mind, and not demonstrate and talk about, like, &amp;#x27;I&amp;#x27;ve got 1,000 agents working together,&amp;#x27; because I think that&amp;#x27;s unrealistic.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Slackbot costs nothing extra, but Salesforce&amp;#x27;s data access fees could squeeze some customers&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Slackbot is included at no additional cost for customers on &lt;a href=&quot;https://slack.com/pricing/businessplus&quot;&gt;Business+&lt;/a&gt; and &lt;a href=&quot;https://slack.com/enterprise&quot;&gt;Enterprise+&lt;/a&gt; plans. &amp;quot;There&amp;#x27;s no additional fees customers have to do,&amp;quot; Gavin confirmed. &amp;quot;If they&amp;#x27;re on one of those plans, they&amp;#x27;re going to get Slackbot.&amp;quot;&lt;/p&gt;&lt;p&gt;However, some enterprise customers may face other cost pressures related to Salesforce&amp;#x27;s broader data strategy. CIOs may see price increases for third-party applications that work with Salesforce data, as effects of higher charges for API access ripple through the software supply chain.&lt;/p&gt;&lt;p&gt;Fivetran CEO George Fraser has warned that Salesforce&amp;#x27;s shift in pricing policy for API access could have tangible consequences for enterprises relying on Salesforce as a system of record. &amp;quot;They might not be able to use Fivetran to replicate their data to Snowflake and instead have to use Salesforce Data Cloud. Or they might find that they are not able to interact with their data via ChatGPT, and instead have to use Agentforce,&amp;quot; Fraser said in a &lt;a href=&quot;https://www.cio.com/article/4108001/salesforce-is-tightening-control-of-its-data-ecosystem-and-cios-may-have-to-pay-the-price.html&quot;&gt;recent CIO report&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Salesforce has framed the pricing change as standard industry practice.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;What Slackbot can do today, what&amp;#x27;s coming in weeks, and what&amp;#x27;s still on the roadmap&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The new Slackbot begins rolling out today and will reach all eligible customers by the end of February. Mobile availability will complete by March 3, Bauer confirmed during her interview with VentureBeat.&lt;/p&gt;&lt;p&gt;Some capabilities remain works in progress. Calendar reading and availability checking are available at launch, but the ability to actually book meetings is &amp;quot;coming a few weeks after,&amp;quot; according to Seaman. Image generation is not currently supported, though Bauer said it&amp;#x27;s &amp;quot;something that we are looking at in the future.&amp;quot;&lt;/p&gt;&lt;p&gt;When asked about integration with competing CRM systems like &lt;a href=&quot;https://www.hubspot.com/&quot;&gt;HubSpot&lt;/a&gt; and &lt;a href=&quot;https://www.microsoft.com/en-us/dynamics-365&quot;&gt;Microsoft Dynamics&lt;/a&gt;, Salesforce representatives declined to provide specifics during the interview, though they acknowledged the question touched on key competitive differentiators.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Salesforce is betting the future of work looks like a chat window—and it&amp;#x27;s not alone&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The Slackbot launch is Salesforce&amp;#x27;s bet that the future of enterprise work is conversational — that employees will increasingly prefer to interact with AI through natural language rather than navigating traditional software interfaces.&lt;/p&gt;&lt;p&gt;Harris described Slack&amp;#x27;s product philosophy using principles like &amp;quot;don&amp;#x27;t make me think&amp;quot; and &amp;quot;be a great host.&amp;quot; The goal, he said, is for Slackbot to surface information proactively rather than requiring users to hunt for it.&lt;/p&gt;&lt;p&gt;&amp;quot;One of the revelations for me is LLMs applied to unstructured information are incredible,&amp;quot; Harris said. &amp;quot;And the amount of value you have if you&amp;#x27;re a Slack user, if your corporation uses Slack — the amount of value in Slack is unbelievable. Because you&amp;#x27;re talking about work, you&amp;#x27;re sharing documents, you&amp;#x27;re making decisions, but you can&amp;#x27;t as a human go through that and really get the same value that an LLM can do.&amp;quot;&lt;/p&gt;&lt;p&gt;Looking ahead, Harris expects the interfaces themselves to evolve beyond pure conversation. &amp;quot;We&amp;#x27;re kind of saturating what we can do with purely conversational UIs,&amp;quot; he said. &amp;quot;I think we&amp;#x27;ll start to see agents building an interface that best suits your intent, as opposed to trying to surface something within a conversational interface that matches your intent.&amp;quot;&lt;/p&gt;&lt;p&gt;Microsoft, Google, and a growing roster of AI startups are placing similar bets — that the winning enterprise AI will be the one embedded in the tools workers already use, not another application to learn. The race to become that invisible layer of workplace intelligence is now fully underway.&lt;/p&gt;&lt;p&gt;For Salesforce, the stakes extend beyond a single product launch. After a &lt;a href=&quot;https://www.investopedia.com/can-salesforce-stock-recover-here-s-what-wall-street-thinks-crm-earnings-11862399&quot;&gt;bruising year&lt;/a&gt; on Wall Street and persistent questions about whether AI threatens its core business, the company is wagering that Slackbot can prove the opposite — that the tens of millions of people already chatting in Slack every day is not a vulnerability, but an unassailable advantage.&lt;/p&gt;&lt;p&gt;Haley Gault, the Salesforce account executive in Pittsburgh who stumbled upon the new Slackbot on a snowy morning, captured the shift in a single sentence: &amp;quot;I honestly can&amp;#x27;t imagine working for another company not having access to these types of tools. This is just how I work now.&amp;quot;&lt;/p&gt;&lt;p&gt;That&amp;#x27;s precisely what Salesforce is counting on.&lt;/p&gt; </p> <a href="https://venturebeat.com/technology/salesforce-rolls-out-new-slackbot-ai-agent-as-it-battles-microsoft-and" target="_blank" class="inline-flex items-center gap-3 px-8 py-3.5 rounded-full bg-blue-600 text-white font-bold" onclick="event.stopPropagation();">
Read More →
</a> </div> </div> </div><div class="resource-card group relative w-full bg-zinc-900/20 border border-zinc-800/80 rounded-[3rem] overflow-hidden transition-all duration-500 cursor-pointer" data-expanded="false"> <div class="flex items-center justify-between p-8 md:p-10 w-full"> <div class="flex items-center gap-8"> <div class="shrink-0 px-4 py-1.5 rounded-full bg-blue-500/10 border border-blue-500/20 text-blue-400 font-mono text-[10px] font-bold uppercase tracking-widest"> Module </div> <h3 class="text-xl md:text-2xl font-bold text-white group-hover:text-blue-400"> Claude Code costs up to $200 a month. Goose does the same thing for free. </h3> </div> <div class="icon-circle w-12 h-12 rounded-full bg-zinc-800 flex items-center justify-center transition-all duration-500 group-hover:bg-blue-600"> <svg xmlns="http://www.w3.org/2000/svg" class="w-6 h-6 text-white chevron-icon transition-transform duration-500" fill="none" viewBox="0 0 24 24" stroke="currentColor"> <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" d="M19 9l-7 7-7-7"></path> </svg> </div> </div> <div class="expand-wrapper overflow-hidden transition-all duration-700 ease-in-out"> <div class="px-10 md:px-20 pb-12 pt-4 border-t border-zinc-800/50"> <p class="text-zinc-300 text-lg leading-relaxed mb-8"> &lt;p&gt;The artificial intelligence coding revolution comes with a catch: it&amp;#x27;s expensive.&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://claude.com/product/claude-code&quot;&gt;Claude Code&lt;/a&gt;, Anthropic&amp;#x27;s terminal-based AI agent that can write, debug, and deploy code autonomously, has captured the imagination of software developers worldwide. But its &lt;a href=&quot;https://claude.com/pricing&quot;&gt;pricing&lt;/a&gt; — ranging from $20 to $200 per month depending on usage — has sparked a growing rebellion among the very programmers it aims to serve.&lt;/p&gt;&lt;p&gt;Now, a free alternative is gaining traction. &lt;a href=&quot;https://block.github.io/goose/&quot;&gt;Goose&lt;/a&gt;, an open-source AI agent developed by &lt;a href=&quot;https://block.xyz/&quot;&gt;Block&lt;/a&gt; (the financial technology company formerly known as Square), offers nearly identical functionality to &lt;a href=&quot;https://claude.com/product/claude-code&quot;&gt;Claude Code&lt;/a&gt; but runs entirely on a user&amp;#x27;s local machine. No subscription fees. No cloud dependency. No rate limits that reset every five hours.&lt;/p&gt;&lt;p&gt;&amp;quot;Your data stays with you, period,&amp;quot; said Parth Sareen, a software engineer who demonstrated the tool during a &lt;a href=&quot;https://www.youtube.com/watch?v=WG10r2N0IwM&quot;&gt;recent livestream&lt;/a&gt;. The comment captures the core appeal: Goose gives developers complete control over their AI-powered workflow, including the ability to work offline — even on an airplane.&lt;/p&gt;&lt;p&gt;The project has exploded in popularity. Goose now boasts more than &lt;a href=&quot;https://github.com/block/goose&quot;&gt;26,100 stars on GitHub&lt;/a&gt;, the code-sharing platform, with 362 contributors and 102 releases since its launch. The latest version, &lt;a href=&quot;https://block.github.io/goose/docs/getting-started/installation&quot;&gt;1.20.1&lt;/a&gt;, shipped on January 19, 2026, reflecting a development pace that rivals commercial products.&lt;/p&gt;&lt;p&gt;For developers frustrated by Claude Code&amp;#x27;s pricing structure and usage caps, Goose represents something increasingly rare in the AI industry: a genuinely free, no-strings-attached option for serious work.&lt;/p&gt;&lt;div&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;Anthropic&amp;#x27;s new rate limits spark a developer revolt&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;To understand why &lt;a href=&quot;https://block.github.io/goose/&quot;&gt;Goose&lt;/a&gt; matters, you need to understand the &lt;a href=&quot;https://techcrunch.com/2025/07/17/anthropic-tightens-usage-limits-for-claude-code-without-telling-users/&quot;&gt;Claude Code pricing controversy&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Anthropic, the San Francisco artificial intelligence company founded by former OpenAI executives, offers Claude Code as part of its subscription tiers. The free plan provides no access whatsoever. The &lt;a href=&quot;https://www.anthropic.com/news/claude-pro&quot;&gt;Pro plan&lt;/a&gt;, at $17 per month with annual billing (or $20 monthly), limits users to just 10 to 40 prompts every five hours — a constraint that serious developers exhaust within minutes of intensive work.&lt;/p&gt;&lt;p&gt;The &lt;a href=&quot;https://support.claude.com/en/articles/11049741-what-is-the-max-plan&quot;&gt;Max plans&lt;/a&gt;, at $100 and $200 per month, offer more headroom: 50 to 200 prompts and 200 to 800 prompts respectively, plus access to Anthropic&amp;#x27;s most powerful model, &lt;a href=&quot;https://www.anthropic.com/news/claude-opus-4-5&quot;&gt;Claude 4.5 Opus&lt;/a&gt;. But even these premium tiers come with restrictions that have inflamed the developer community.&lt;/p&gt;&lt;p&gt;In late July, Anthropic announced new weekly rate limits. Under the system, Pro users receive 40 to 80 hours of Sonnet 4 usage per week. Max users at the $200 tier get 240 to 480 hours of Sonnet 4, plus 24 to 40 hours of Opus 4. Nearly five months later, the frustration has not subsided.&lt;/p&gt;&lt;p&gt;The problem? Those &amp;quot;hours&amp;quot; are not actual hours. They represent token-based limits that vary wildly depending on codebase size, conversation length, and the complexity of the code being processed. Independent analysis suggests the actual per-session limits translate to roughly 44,000 tokens for Pro users and 220,000 tokens for the $200 Max plan.&lt;/p&gt;&lt;p&gt;&amp;quot;It&amp;#x27;s confusing and vague,&amp;quot; one developer wrote in a &lt;a href=&quot;https://userjot.com/blog/claude-code-pricing-200-dollar-plan-worth-it&quot;&gt;widely shared analysis&lt;/a&gt;. &amp;quot;When they say &amp;#x27;24-40 hours of Opus 4,&amp;#x27; that doesn&amp;#x27;t really tell you anything useful about what you&amp;#x27;re actually getting.&amp;quot;&lt;/p&gt;&lt;p&gt;The &lt;a href=&quot;https://www.reddit.com/r/Anthropic/comments/1mbo4uw/claude_code_max_new_weekly_rate_limits/&quot;&gt;backlash on Reddit&lt;/a&gt; and &lt;a href=&quot;https://venturebeat.com/ai/anthropic-throttles-claude-rate-limits-devs-call-foul&quot;&gt;developer forums&lt;/a&gt; has been fierce. Some users report hitting their daily limits within 30 minutes of intensive coding. Others have canceled their subscriptions entirely, calling the new restrictions &amp;quot;a joke&amp;quot; and &amp;quot;unusable for real work.&amp;quot;&lt;/p&gt;&lt;p&gt;Anthropic has defended the changes, stating that the limits affect fewer than five percent of users and target people running Claude Code &amp;quot;&lt;a href=&quot;https://techcrunch.com/2025/07/28/anthropic-unveils-new-rate-limits-to-curb-claude-code-power-users/&quot;&gt;continuously in the background, 24/7&lt;/a&gt;.&amp;quot; But the company has not clarified whether that figure refers to five percent of Max subscribers or five percent of all users — a distinction that matters enormously.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How Block built a free AI coding agent that works offline&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://block.github.io/goose/&quot;&gt;Goose&lt;/a&gt; takes a radically different approach to the same problem.&lt;/p&gt;&lt;p&gt;Built by &lt;a href=&quot;https://block.xyz/&quot;&gt;Block&lt;/a&gt;, the payments company led by Jack Dorsey, Goose is what engineers call an &amp;quot;&lt;a href=&quot;https://github.com/block/goose&quot;&gt;on-machine AI agent&lt;/a&gt;.&amp;quot; Unlike Claude Code, which sends your queries to Anthropic&amp;#x27;s servers for processing, Goose can run entirely on your local computer using open-source language models that you download and control yourself.&lt;/p&gt;&lt;p&gt;The project&amp;#x27;s documentation describes it as going &amp;quot;&lt;a href=&quot;https://github.com/block/goose&quot;&gt;beyond code suggestions&lt;/a&gt;&amp;quot; to &amp;quot;install, execute, edit, and test with any LLM.&amp;quot; That last phrase — &amp;quot;any LLM&amp;quot; — is the key differentiator. Goose is model-agnostic by design.&lt;/p&gt;&lt;p&gt;You can connect Goose to Anthropic&amp;#x27;s &lt;a href=&quot;https://platform.claude.com/docs/en/about-claude/models/overview&quot;&gt;Claude models&lt;/a&gt; if you have &lt;a href=&quot;https://claude.com/platform/api&quot;&gt;API access&lt;/a&gt;. You can use OpenAI&amp;#x27;s &lt;a href=&quot;https://platform.openai.com/docs/models/gpt-5&quot;&gt;GPT-5&lt;/a&gt; or Google&amp;#x27;s &lt;a href=&quot;https://ai.google.dev/gemini-api/docs&quot;&gt;Gemini&lt;/a&gt;. You can route it through services like &lt;a href=&quot;https://groq.com/&quot;&gt;Groq&lt;/a&gt; or &lt;a href=&quot;https://openrouter.ai/&quot;&gt;OpenRouter&lt;/a&gt;. Or — and this is where things get interesting — you can run it entirely locally using tools like &lt;a href=&quot;https://ollama.com/&quot;&gt;Ollama&lt;/a&gt;, which let you download and execute open-source models on your own hardware.&lt;/p&gt;&lt;p&gt;The practical implications are significant. With a local setup, there are no subscription fees, no usage caps, no rate limits, and no concerns about your code being sent to external servers. Your conversations with the AI never leave your machine.&lt;/p&gt;&lt;p&gt;&amp;quot;I use Ollama all the time on planes — it&amp;#x27;s a lot of fun!&amp;quot; &lt;a href=&quot;https://www.youtube.com/watch?v=WG10r2N0IwM&quot;&gt;Sareen noted&lt;/a&gt; during a demonstration, highlighting how local models free developers from the constraints of internet connectivity.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;What Goose can do that traditional code assistants can&amp;#x27;t&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://block.github.io/goose/&quot;&gt;Goose&lt;/a&gt; operates as a command-line tool or desktop application that can autonomously perform complex development tasks. It can build entire projects from scratch, write and execute code, debug failures, orchestrate workflows across multiple files, and interact with external APIs — all without constant human oversight.&lt;/p&gt;&lt;p&gt;The architecture relies on what the AI industry calls &amp;quot;&lt;a href=&quot;https://www.ibm.com/think/topics/tool-calling&quot;&gt;tool calling&lt;/a&gt;&amp;quot; or &amp;quot;&lt;a href=&quot;https://platform.openai.com/docs/guides/function-calling?api-mode=chat&quot;&gt;function calling&lt;/a&gt;&amp;quot; — the ability for a language model to request specific actions from external systems. When you ask &lt;a href=&quot;https://block.github.io/goose/&quot;&gt;Goose&lt;/a&gt; to create a new file, run a test suite, or check the status of a GitHub pull request, it doesn&amp;#x27;t just generate text describing what should happen. It actually executes those operations.&lt;/p&gt;&lt;p&gt;This capability depends heavily on the underlying language model. &lt;a href=&quot;https://platform.claude.com/docs/en/about-claude/models/overview&quot;&gt;Claude 4 models&lt;/a&gt; from Anthropic currently perform best at tool calling, according to the &lt;a href=&quot;https://gorilla.cs.berkeley.edu/leaderboard.html&quot;&gt;Berkeley Function-Calling Leaderboard&lt;/a&gt;, which ranks models on their ability to translate natural language requests into executable code and system commands.&lt;/p&gt;&lt;p&gt;But newer open-source models are catching up quickly. Goose&amp;#x27;s documentation highlights several options with strong tool-calling support: Meta&amp;#x27;s &lt;a href=&quot;https://www.llama.com/&quot;&gt;Llama series&lt;/a&gt;, Alibaba&amp;#x27;s &lt;a href=&quot;https://qwen.ai/home&quot;&gt;Qwen models&lt;/a&gt;, Google&amp;#x27;s &lt;a href=&quot;https://deepmind.google/models/gemma/&quot;&gt;Gemma variants&lt;/a&gt;, and DeepSeek&amp;#x27;s &lt;a href=&quot;https://huggingface.co/deepseek-ai/DeepSeek-R1&quot;&gt;reasoning-focused architectures&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;The tool also integrates with the &lt;a href=&quot;https://modelcontextprotocol.io/docs/getting-started/intro&quot;&gt;Model Context Protocol&lt;/a&gt;, or MCP, an emerging standard for connecting AI agents to external services. Through MCP, Goose can access databases, search engines, file systems, and third-party APIs — extending its capabilities far beyond what the base language model provides.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Setting Up Goose with a Local Model&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;For developers interested in a completely free, privacy-preserving setup, the process involves three main components: &lt;a href=&quot;https://block.github.io/goose/&quot;&gt;Goose&lt;/a&gt; itself, &lt;a href=&quot;https://ollama.com/&quot;&gt;Ollama&lt;/a&gt; (a tool for running open-source models locally), and a compatible language model.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Step 1: Install Ollama&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://ollama.com/&quot;&gt;Ollama&lt;/a&gt; is an open-source project that dramatically simplifies the process of running large language models on personal hardware. It handles the complex work of downloading, optimizing, and serving models through a simple interface.&lt;/p&gt;&lt;p&gt;Download and install Ollama from &lt;a href=&quot;http://ollama.com&quot;&gt;ollama.com&lt;/a&gt;. Once installed, you can pull models with a single command. For coding tasks, &lt;a href=&quot;https://qwen.ai/blog?id=qwen2.5-max&quot;&gt;Qwen 2.5&lt;/a&gt; offers strong tool-calling support:&lt;/p&gt;&lt;p&gt;ollama run qwen2.5&lt;/p&gt;&lt;p&gt;The model downloads automatically and begins running on your machine.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Step 2: Install Goose&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://block.github.io/goose/&quot;&gt;Goose&lt;/a&gt; is available as both a desktop application and a command-line interface. The desktop version provides a more visual experience, while the CLI appeals to developers who prefer working entirely in the terminal.&lt;/p&gt;&lt;p&gt;Installation instructions vary by operating system but generally involve downloading from Goose&amp;#x27;s &lt;a href=&quot;https://github.com/block/goose&quot;&gt;GitHub releases page&lt;/a&gt; or using a package manager. Block provides pre-built binaries for macOS (both Intel and Apple Silicon), Windows, and Linux.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Step 3: Configure the Connection&lt;/b&gt;&lt;/p&gt;&lt;p&gt;In Goose Desktop, navigate to Settings, then Configure Provider, and select Ollama. Confirm that the API Host is set to http://localhost:11434 (Ollama&amp;#x27;s default port) and click Submit.&lt;/p&gt;&lt;p&gt;For the command-line version, run goose configure, select &amp;quot;Configure Providers,&amp;quot; choose Ollama, and enter the model name when prompted.&lt;/p&gt;&lt;p&gt;That&amp;#x27;s it. Goose is now connected to a language model running entirely on your hardware, ready to execute complex coding tasks without any subscription fees or external dependencies.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The RAM, processing power, and trade-offs you should know about&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The obvious question: what kind of computer do you need?&lt;/p&gt;&lt;p&gt;Running large language models locally requires substantially more computational resources than typical software. The key constraint is memory — specifically, RAM on most systems, or VRAM if using a dedicated graphics card for acceleration.&lt;/p&gt;&lt;p&gt;Block&amp;#x27;s &lt;a href=&quot;https://block.github.io/goose/docs/category/guides&quot;&gt;documentation&lt;/a&gt; suggests that 32 gigabytes of RAM provides &amp;quot;a solid baseline for larger models and outputs.&amp;quot; For Mac users, this means the computer&amp;#x27;s unified memory is the primary bottleneck. For Windows and Linux users with discrete NVIDIA graphics cards, GPU memory (VRAM) matters more for acceleration.&lt;/p&gt;&lt;p&gt;But you don&amp;#x27;t necessarily need expensive hardware to get started. Smaller models with fewer parameters run on much more modest systems. &lt;a href=&quot;https://qwen.ai/blog?id=qwen2.5-max&quot;&gt;Qwen 2.5&lt;/a&gt;, for instance, comes in multiple sizes, and the smaller variants can operate effectively on machines with 16 gigabytes of RAM.&lt;/p&gt;&lt;p&gt;&amp;quot;You don&amp;#x27;t need to run the largest models to get excellent results,&amp;quot; &lt;a href=&quot;https://www.youtube.com/watch?v=WG10r2N0IwM&quot;&gt;Sareen emphasized&lt;/a&gt;. The practical recommendation: start with a smaller model to test your workflow, then scale up as needed.&lt;/p&gt;&lt;p&gt;For context, Apple&amp;#x27;s entry-level &lt;a href=&quot;https://www.apple.com/macbook-air/&quot;&gt;MacBook Air&lt;/a&gt; with 8 gigabytes of RAM would struggle with most capable coding models. But a &lt;a href=&quot;https://www.apple.com/macbook-pro/&quot;&gt;MacBook Pro&lt;/a&gt; with 32 gigabytes — increasingly common among professional developers — handles them comfortably.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why keeping your code off the cloud matters more than ever&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://block.github.io/goose/&quot;&gt;Goose&lt;/a&gt; with a local LLM is not a perfect substitute for &lt;a href=&quot;https://claude.com/product/claude-code&quot;&gt;Claude Code&lt;/a&gt;. The comparison involves real trade-offs that developers should understand.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Model Quality&lt;/b&gt;: &lt;a href=&quot;https://www.anthropic.com/news/claude-opus-4-5&quot;&gt;Claude 4.5 Opus&lt;/a&gt;, Anthropic&amp;#x27;s flagship model, remains arguably the most capable AI for software engineering tasks. It excels at understanding complex codebases, following nuanced instructions, and producing high-quality code on the first attempt. Open-source models have improved dramatically, but a gap persists — particularly for the most challenging tasks.&lt;/p&gt;&lt;p&gt;One developer who switched to the $200 Claude Code plan &lt;a href=&quot;https://userjot.com/blog/claude-code-pricing-200-dollar-plan-worth-it&quot;&gt;described the difference bluntly&lt;/a&gt;: &amp;quot;When I say &amp;#x27;make this look modern,&amp;#x27; Opus knows what I mean. Other models give me Bootstrap circa 2015.&amp;quot;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Context Window&lt;/b&gt;: &lt;a href=&quot;https://www.anthropic.com/news/claude-sonnet-4-5&quot;&gt;Claude Sonnet 4.5&lt;/a&gt;, accessible through the API, offers a massive one-million-token context window — enough to load entire large codebases without chunking or context management issues. Most local models are limited to 4,096 or 8,192 tokens by default, though many can be configured for longer contexts at the cost of increased memory usage and slower processing.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Speed&lt;/b&gt;: Cloud-based services like &lt;a href=&quot;https://claude.com/product/claude-code&quot;&gt;Claude Code&lt;/a&gt; run on dedicated server hardware optimized for AI inference. Local models, running on consumer laptops, typically process requests more slowly. The difference matters for iterative workflows where you&amp;#x27;re making rapid changes and waiting for AI feedback.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Tooling Maturity&lt;/b&gt;: &lt;a href=&quot;https://claude.com/product/claude-code&quot;&gt;Claude Code&lt;/a&gt; benefits from Anthropic&amp;#x27;s dedicated engineering resources. Features like prompt caching (which can reduce costs by up to 90 percent for repeated contexts) and structured outputs are polished and well-documented. &lt;a href=&quot;https://block.github.io/goose/&quot;&gt;Goose&lt;/a&gt;, while actively developed with 102 releases to date, relies on community contributions and may lack equivalent refinement in specific areas.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How Goose stacks up against Cursor, GitHub Copilot, and the paid AI coding market&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Goose enters a crowded market of AI coding tools, but occupies a distinctive position.&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://cursor.com/&quot;&gt;Cursor&lt;/a&gt;, a popular AI-enhanced code editor, charges $20 per month for its &lt;a href=&quot;https://cursor.com/pricing&quot;&gt;Pro tier&lt;/a&gt; and $200 for &lt;a href=&quot;https://cursor.com/pricing&quot;&gt;Ultra&lt;/a&gt;—pricing that mirrors &lt;a href=&quot;https://claude.com/pricing&quot;&gt;Claude Code&amp;#x27;s Max plans&lt;/a&gt;. Cursor provides approximately 4,500 Sonnet 4 requests per month at the Ultra level, a substantially different allocation model than Claude Code&amp;#x27;s hourly resets.&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://cline.bot/&quot;&gt;Cline&lt;/a&gt;, &lt;a href=&quot;https://roocode.com/&quot;&gt;Roo Code&lt;/a&gt;, and similar open-source projects offer AI coding assistance but with varying levels of autonomy and tool integration. Many focus on code completion rather than the agentic task execution that defines Goose and Claude Code.&lt;/p&gt;&lt;p&gt;Amazon&amp;#x27;s &lt;a href=&quot;https://aws.amazon.com/blogs/aws/now-in-preview-amazon-codewhisperer-ml-powered-coding-companion/&quot;&gt;CodeWhisperer&lt;/a&gt;, &lt;a href=&quot;https://github.com/features/copilot&quot;&gt;GitHub Copilot&lt;/a&gt;, and enterprise offerings from major cloud providers target large organizations with complex procurement processes and dedicated budgets. They are less relevant to individual developers and small teams seeking lightweight, flexible tools.&lt;/p&gt;&lt;p&gt;Goose&amp;#x27;s combination of genuine autonomy, model agnosticism, local operation, and zero cost creates a unique value proposition. The tool is not trying to compete with commercial offerings on polish or model quality. It&amp;#x27;s competing on freedom — both financial and architectural.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The $200-a-month era for AI coding tools may be ending&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The AI coding tools market is evolving quickly. Open-source models are improving at a pace that continually narrows the gap with proprietary alternatives. Moonshot AI&amp;#x27;s &lt;a href=&quot;https://www.kimi.com/en&quot;&gt;Kimi K2&lt;/a&gt; and z.ai&amp;#x27;s &lt;a href=&quot;https://z.ai/blog/glm-4.5&quot;&gt;GLM 4.5&lt;/a&gt; now benchmark near &lt;a href=&quot;https://www.anthropic.com/news/claude-4&quot;&gt;Claude Sonnet 4 levels&lt;/a&gt; — and they&amp;#x27;re freely available.&lt;/p&gt;&lt;p&gt;If this trajectory continues, the quality advantage that justifies Claude Code&amp;#x27;s premium pricing may erode. Anthropic would then face pressure to compete on features, user experience, and integration rather than raw model capability.&lt;/p&gt;&lt;p&gt;For now, developers face a clear choice. Those who need the absolute best model quality, who can afford premium pricing, and who accept usage restrictions may prefer &lt;a href=&quot;https://claude.com/product/claude-code&quot;&gt;Claude Code&lt;/a&gt;. Those who prioritize cost, privacy, offline access, and flexibility have a genuine alternative in &lt;a href=&quot;https://block.github.io/goose/&quot;&gt;Goose&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;The fact that a $200-per-month commercial product has a zero-dollar open-source competitor with comparable core functionality is itself remarkable. It reflects both the maturation of open-source AI infrastructure and the appetite among developers for tools that respect their autonomy.&lt;/p&gt;&lt;p&gt;Goose is not perfect. It requires more technical setup than commercial alternatives. It depends on hardware resources that not every developer possesses. Its model options, while improving rapidly, still trail the best proprietary offerings on complex tasks.&lt;/p&gt;&lt;p&gt;But for a growing community of developers, those limitations are acceptable trade-offs for something increasingly rare in the AI landscape: a tool that truly belongs to them.&lt;/p&gt;&lt;hr /&gt;&lt;p&gt;&lt;i&gt;Goose is available for download at &lt;/i&gt;&lt;a href=&quot;http://github.com/block/goose&quot;&gt;&lt;i&gt;github.com/block/goose&lt;/i&gt;&lt;/a&gt;&lt;i&gt;. Ollama is available at &lt;/i&gt;&lt;a href=&quot;http://ollama.com&quot;&gt;&lt;i&gt;ollama.com&lt;/i&gt;&lt;/a&gt;&lt;i&gt;. Both projects are free and open source.&lt;/i&gt;&lt;/p&gt; </p> <a href="https://venturebeat.com/technology/claude-code-costs-up-to-usd200-a-month-goose-does-the-same-thing-for-free" target="_blank" class="inline-flex items-center gap-3 px-8 py-3.5 rounded-full bg-blue-600 text-white font-bold" onclick="event.stopPropagation();">
Read More →
</a> </div> </div> </div><div class="resource-card group relative w-full bg-zinc-900/20 border border-zinc-800/80 rounded-[3rem] overflow-hidden transition-all duration-500 cursor-pointer" data-expanded="false"> <div class="flex items-center justify-between p-8 md:p-10 w-full"> <div class="flex items-center gap-8"> <div class="shrink-0 px-4 py-1.5 rounded-full bg-blue-500/10 border border-blue-500/20 text-blue-400 font-mono text-[10px] font-bold uppercase tracking-widest"> LangChain </div> <h3 class="text-xl md:text-2xl font-bold text-white group-hover:text-blue-400"> Using skills with Deep Agents </h3> </div> <div class="icon-circle w-12 h-12 rounded-full bg-zinc-800 flex items-center justify-center transition-all duration-500 group-hover:bg-blue-600"> <svg xmlns="http://www.w3.org/2000/svg" class="w-6 h-6 text-white chevron-icon transition-transform duration-500" fill="none" viewBox="0 0 24 24" stroke="currentColor"> <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" d="M19 9l-7 7-7-7"></path> </svg> </div> </div> <div class="expand-wrapper overflow-hidden transition-all duration-700 ease-in-out"> <div class="px-10 md:px-20 pb-12 pt-4 border-t border-zinc-800/50"> <p class="text-zinc-300 text-lg leading-relaxed mb-8"> Anthropic has introduced a novel concept in AI called &quot;agent skills&quot;, which are essentially folders containing a SKILL.md file and associated resources that agents can dynamically load to enhance task performance. This approach, now integrated into the deepagents-CLI, allows general-purpose agents like Claude Code and Manus to operate effectively with a minimal set of tools by leveraging computer access, including bash and filesystem utilities. The innovation lies in enabling agents to perform diverse actions using a computer&#39;s inherent capabilities, rather than relying on a multitude of specialized tools, thereby streamlining their operational framework.

The strategic impact of this development is significant for the AI ecosystem as it shifts the paradigm from tool-heavy to skill-based agentic AI. By offloading actions to the filesystem and utilizing scripts, agents can achieve a broader range of capabilities with fewer resources, enhancing efficiency and reducing cognitive load. This method not only optimizes token usage by progressively disclosing information but also simplifies the agent&#39;s operational context, which can lead to more robust and adaptable AI systems. The ability to share and compose skills across different agents further amplifies the potential for collaborative and scalable AI solutions.

Experts see this as a pivotal step towards continuous learning and adaptability in AI systems. Skills enable agents to dynamically create and integrate new capabilities as they encounter novel tasks, fostering an environment of continuous improvement and innovation. However, the reliance on filesystem operations may introduce security considerations that need addressing. The future trajectory of this approach suggests a move towards more autonomous and self-improving AI agents, with the potential to revolutionize how AI systems are developed and deployed across various industries. </p> <a href="https://www.blog.langchain.com/using-skills-with-deep-agents/" target="_blank" class="inline-flex items-center gap-3 px-8 py-3.5 rounded-full bg-blue-600 text-white font-bold" onclick="event.stopPropagation();">
Read More →
</a> </div> </div> </div><div class="resource-card group relative w-full bg-zinc-900/20 border border-zinc-800/80 rounded-[3rem] overflow-hidden transition-all duration-500 cursor-pointer" data-expanded="false"> <div class="flex items-center justify-between p-8 md:p-10 w-full"> <div class="flex items-center gap-8"> <div class="shrink-0 px-4 py-1.5 rounded-full bg-blue-500/10 border border-blue-500/20 text-blue-400 font-mono text-[10px] font-bold uppercase tracking-widest"> LangChain </div> <h3 class="text-xl md:text-2xl font-bold text-white group-hover:text-blue-400"> Choosing the Right Multi-Agent Architecture </h3> </div> <div class="icon-circle w-12 h-12 rounded-full bg-zinc-800 flex items-center justify-center transition-all duration-500 group-hover:bg-blue-600"> <svg xmlns="http://www.w3.org/2000/svg" class="w-6 h-6 text-white chevron-icon transition-transform duration-500" fill="none" viewBox="0 0 24 24" stroke="currentColor"> <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" d="M19 9l-7 7-7-7"></path> </svg> </div> </div> <div class="expand-wrapper overflow-hidden transition-all duration-700 ease-in-out"> <div class="px-10 md:px-20 pb-12 pt-4 border-t border-zinc-800/50"> <p class="text-zinc-300 text-lg leading-relaxed mb-8"> The article by Sydney Runkle explores the intricacies of multi-agent architectures in AI, emphasizing the transition from single-agent systems to more complex multi-agent setups. As applications grow in complexity and scale, the need for integrating multiple agent capabilities into a cohesive interface becomes evident. The article highlights four primary architectural patterns—subagents, skills, handoffs, and routers—that facilitate this integration, each with distinct approaches to task coordination and state management. These patterns enable distributed reasoning and context management, essential for handling extensive domain knowledge and coordinating across teams.

The strategic impact of adopting multi-agent architectures is significant for the AI ecosystem, as it allows for more efficient handling of complex tasks that single-agent systems struggle with. By distributing work across multiple agents, organizations can achieve parallel reasoning and better manage context, which is crucial in scenarios with sprawling capabilities and independent team development. This approach not only enhances performance, as demonstrated by Anthropic’s research, but also supports distributed development and ownership, making it a valuable strategy for businesses looking to scale their AI applications effectively.

Experts should note that while multi-agent architectures offer substantial benefits, they also introduce new challenges, such as increased latency and the need for careful state management. The choice of architecture depends on the specific constraints and requirements of the application, with each pattern offering unique trade-offs. As AI systems continue to evolve, the development and refinement of multi-agent architectures will be crucial in addressing the growing complexity of agentic tasks, ensuring that AI remains adaptable and capable of meeting diverse business needs. </p> <a href="https://www.blog.langchain.com/choosing-the-right-multi-agent-architecture/" target="_blank" class="inline-flex items-center gap-3 px-8 py-3.5 rounded-full bg-blue-600 text-white font-bold" onclick="event.stopPropagation();">
Read More →
</a> </div> </div> </div><div class="resource-card group relative w-full bg-zinc-900/20 border border-zinc-800/80 rounded-[3rem] overflow-hidden transition-all duration-500 cursor-pointer" data-expanded="false"> <div class="flex items-center justify-between p-8 md:p-10 w-full"> <div class="flex items-center gap-8"> <div class="shrink-0 px-4 py-1.5 rounded-full bg-blue-500/10 border border-blue-500/20 text-blue-400 font-mono text-[10px] font-bold uppercase tracking-widest"> Module </div> <h3 class="text-xl md:text-2xl font-bold text-white group-hover:text-blue-400"> The creator of Claude Code just revealed his workflow, and developers are losing their minds </h3> </div> <div class="icon-circle w-12 h-12 rounded-full bg-zinc-800 flex items-center justify-center transition-all duration-500 group-hover:bg-blue-600"> <svg xmlns="http://www.w3.org/2000/svg" class="w-6 h-6 text-white chevron-icon transition-transform duration-500" fill="none" viewBox="0 0 24 24" stroke="currentColor"> <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" d="M19 9l-7 7-7-7"></path> </svg> </div> </div> <div class="expand-wrapper overflow-hidden transition-all duration-700 ease-in-out"> <div class="px-10 md:px-20 pb-12 pt-4 border-t border-zinc-800/50"> <p class="text-zinc-300 text-lg leading-relaxed mb-8"> &lt;p&gt;When the creator of the world&amp;#x27;s most advanced coding agent speaks, Silicon Valley doesn&amp;#x27;t just listen — it takes notes.&lt;/p&gt;&lt;p&gt;For the past week, the engineering community has been dissecting a &lt;a href=&quot;https://x.com/bcherny/status/2007179832300581177&quot;&gt;thread on X&lt;/a&gt; from &lt;a href=&quot;https://x.com/bcherny&quot;&gt;Boris Cherny&lt;/a&gt;, the creator and head of &lt;a href=&quot;https://code.claude.com/docs/en/overview&quot;&gt;Claude Code&lt;/a&gt; at &lt;a href=&quot;https://www.anthropic.com/&quot;&gt;Anthropic&lt;/a&gt;. What began as a casual sharing of his personal terminal setup has spiraled into a viral manifesto on the future of software development, with industry insiders calling it a watershed moment for the startup.&lt;/p&gt;&lt;div&gt;&lt;/div&gt;&lt;p&gt;&amp;quot;If you&amp;#x27;re not reading the Claude Code best practices straight from its creator, you&amp;#x27;re behind as a programmer,&amp;quot; wrote &lt;a href=&quot;https://x.com/jefftangx&quot;&gt;Jeff Tang&lt;/a&gt;, a prominent voice in the developer community. &lt;a href=&quot;https://x.com/KyleMcnease/status/2007555584724480338&quot;&gt;Kyle McNease&lt;/a&gt;, another industry observer, went further, declaring that with Cherny&amp;#x27;s &amp;quot;game-changing updates,&amp;quot; Anthropic is &amp;quot;on fire,&amp;quot; potentially facing &amp;quot;their ChatGPT moment.&amp;quot;&lt;/p&gt;&lt;p&gt;The excitement stems from a paradox: Cherny&amp;#x27;s workflow is surprisingly simple, yet it allows a single human to operate with the output capacity of a small engineering department. As one user noted on X after implementing Cherny&amp;#x27;s setup, the experience &amp;quot;&lt;a href=&quot;https://x.com/mtwichan&quot;&gt;feels more like Starcraft&lt;/a&gt;&amp;quot; than traditional coding — a shift from typing syntax to commanding autonomous units.&lt;/p&gt;&lt;p&gt;Here is an analysis of the workflow that is reshaping how software gets built, straight from the architect himself. &lt;/p&gt;&lt;h2&gt;&lt;b&gt;How running five AI agents at once turns coding into a real-time strategy game&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The most striking revelation from Cherny&amp;#x27;s disclosure is that he does not code in a linear fashion. In the traditional &amp;quot;&lt;a href=&quot;https://notes.paulswail.com/public/The+inner+and+outer+loops+of+software+development+workflow&quot;&gt;inner loop&lt;/a&gt;&amp;quot; of development, a programmer writes a function, tests it, and moves to the next. Cherny, however, acts as a fleet commander.&lt;/p&gt;&lt;p&gt;&amp;quot;I run 5 Claudes in parallel in my terminal,&amp;quot; Cherny wrote. &amp;quot;I number my tabs 1-5, and use system notifications to know when a Claude needs input.&amp;quot;&lt;/p&gt;&lt;p&gt;By utilizing iTerm2 system notifications, Cherny effectively manages five simultaneous work streams. While one agent runs a test suite, another refactors a legacy module, and a third drafts documentation. He also runs &amp;quot;5-10 Claudes on &lt;a href=&quot;https://claude.ai/&quot;&gt;claude.ai&lt;/a&gt;&amp;quot; in his browser, using a &amp;quot;teleport&amp;quot; command to hand off sessions between the web and his local machine.&lt;/p&gt;&lt;p&gt;This validates the &amp;quot;&lt;a href=&quot;https://www.cnbc.com/2026/01/03/anthropic-daniela-amodei-do-more-with-less-bet.html&quot;&gt;do more with less&lt;/a&gt;&amp;quot; strategy articulated by Anthropic President Daniela Amodei earlier this week. While competitors like OpenAI pursue trillion-dollar infrastructure build-outs, Anthropic is proving that superior orchestration of existing models can yield exponential productivity gains.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The counterintuitive case for choosing the slowest, smartest model&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;In a surprising move for an industry obsessed with latency, Cherny revealed that he exclusively uses Anthropic&amp;#x27;s heaviest, slowest model: &lt;a href=&quot;https://www.anthropic.com/news/claude-opus-4-5&quot;&gt;Opus 4.5&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&amp;quot;I use Opus 4.5 with thinking for everything,&amp;quot; Cherny &lt;a href=&quot;https://x.com/bcherny/status/2007179838864666847&quot;&gt;explained&lt;/a&gt;. &amp;quot;It&amp;#x27;s the best coding model I&amp;#x27;ve ever used, and even though it&amp;#x27;s bigger &amp;amp; slower than Sonnet, since you have to steer it less and it&amp;#x27;s better at tool use, it is almost always faster than using a smaller model in the end.&amp;quot;&lt;/p&gt;&lt;p&gt;For enterprise technology leaders, this is a critical insight. The bottleneck in modern AI development isn&amp;#x27;t the generation speed of the token; it is the human time spent correcting the AI&amp;#x27;s mistakes. Cherny&amp;#x27;s workflow suggests that paying the &amp;quot;compute tax&amp;quot; for a smarter model upfront eliminates the &amp;quot;correction tax&amp;quot; later.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;One shared file turns every AI mistake into a permanent lesson&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Cherny also detailed how his team solves the problem of AI amnesia. Standard large language models do not &amp;quot;remember&amp;quot; a company&amp;#x27;s specific coding style or architectural decisions from one session to the next.&lt;/p&gt;&lt;p&gt;To address this, Cherny&amp;#x27;s team maintains a single file named &lt;a href=&quot;https://x.com/bcherny/status/2007179842928947333&quot;&gt;CLAUDE.md&lt;/a&gt; in their git repository. &amp;quot;Anytime we see Claude do something incorrectly we add it to the CLAUDE.md, so Claude knows not to do it next time,&amp;quot; he wrote.&lt;/p&gt;&lt;p&gt;This practice transforms the codebase into a self-correcting organism. When a human developer reviews a pull request and spots an error, they don&amp;#x27;t just fix the code; they tag the AI to update its own instructions. &amp;quot;&lt;a href=&quot;https://x.com/aakashgupta/status/2007347705945944153&quot;&gt;Every mistake becomes a rule&lt;/a&gt;,&amp;quot; noted &lt;a href=&quot;https://x.com/aakashgupta&quot;&gt;Aakash Gupta&lt;/a&gt;, a product leader analyzing the thread. The longer the team works together, the smarter the agent becomes.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Slash commands and subagents automate the most tedious parts of development&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The &amp;quot;vanilla&amp;quot; workflow one observer praised is powered by rigorous automation of repetitive tasks. Cherny uses slash commands — custom shortcuts checked into the project&amp;#x27;s repository — to handle complex operations with a single keystroke.&lt;/p&gt;&lt;p&gt;He highlighted a command called &lt;i&gt;&lt;b&gt;/commit-push-pr&lt;/b&gt;&lt;/i&gt;, which he invokes dozens of times daily. Instead of manually typing git commands, writing a commit message, and opening a pull request, the agent handles the bureaucracy of version control autonomously.&lt;/p&gt;&lt;p&gt;Cherny also deploys subagents — specialized AI personas — to handle specific phases of the development lifecycle. He uses a code-simplifier to clean up architecture after the main work is done and a verify-app agent to run end-to-end tests before anything ships.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why verification loops are the real unlock for AI-generated code&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;If there is a single reason Claude Code has reportedly hit &lt;a href=&quot;https://www.anthropic.com/news/anthropic-acquires-bun-as-claude-code-reaches-usd1b-milestone&quot;&gt;$1 billion in annual recurring revenue&lt;/a&gt; so quickly, it is likely the verification loop. The AI is not just a text generator; it is a tester.&lt;/p&gt;&lt;p&gt;&amp;quot;Claude tests every single change I land to claude.ai/code using the Claude Chrome extension,&amp;quot; Cherny wrote. &amp;quot;It opens a browser, tests the UI, and iterates until the code works and the UX feels good.&amp;quot;&lt;/p&gt;&lt;p&gt;He argues that giving the AI a way to verify its own work — whether through browser automation, running bash commands, or executing test suites — improves the quality of the final result by &amp;quot;2-3x.&amp;quot; The agent doesn&amp;#x27;t just write code; it proves the code works.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;What Cherny&amp;#x27;s workflow signals about the future of software engineering&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The reaction to Cherny&amp;#x27;s thread suggests a pivotal shift in how developers think about their craft. For years, &amp;quot;AI coding&amp;quot; meant an autocomplete function in a text editor — a faster way to type. Cherny has demonstrated that it can now function as an operating system for labor itself.&lt;/p&gt;&lt;p&gt;&amp;quot;Read this if you&amp;#x27;re already an engineer... and want more power,&amp;quot; &lt;a href=&quot;https://x.com/jefftangx/status/2008246873275215890&quot;&gt;Jeff Tang&lt;/a&gt; summarized on X.&lt;/p&gt;&lt;p&gt;The tools to multiply human output by a factor of five are already here. They require only a willingness to stop thinking of AI as an assistant and start treating it as a workforce. The programmers who make that mental leap first won&amp;#x27;t just be more productive. They&amp;#x27;ll be playing an entirely different game — and everyone else will still be typing.&lt;/p&gt; </p> <a href="https://venturebeat.com/technology/the-creator-of-claude-code-just-revealed-his-workflow-and-developers-are" target="_blank" class="inline-flex items-center gap-3 px-8 py-3.5 rounded-full bg-blue-600 text-white font-bold" onclick="event.stopPropagation();">
Read More →
</a> </div> </div> </div><div class="resource-card group relative w-full bg-zinc-900/20 border border-zinc-800/80 rounded-[3rem] overflow-hidden transition-all duration-500 cursor-pointer" data-expanded="false"> <div class="flex items-center justify-between p-8 md:p-10 w-full"> <div class="flex items-center gap-8"> <div class="shrink-0 px-4 py-1.5 rounded-full bg-blue-500/10 border border-blue-500/20 text-blue-400 font-mono text-[10px] font-bold uppercase tracking-widest"> Module </div> <h3 class="text-xl md:text-2xl font-bold text-white group-hover:text-blue-400"> Nous Research&#39;s NousCoder-14B is an open-source coding model landing right in the Claude Code moment </h3> </div> <div class="icon-circle w-12 h-12 rounded-full bg-zinc-800 flex items-center justify-center transition-all duration-500 group-hover:bg-blue-600"> <svg xmlns="http://www.w3.org/2000/svg" class="w-6 h-6 text-white chevron-icon transition-transform duration-500" fill="none" viewBox="0 0 24 24" stroke="currentColor"> <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" d="M19 9l-7 7-7-7"></path> </svg> </div> </div> <div class="expand-wrapper overflow-hidden transition-all duration-700 ease-in-out"> <div class="px-10 md:px-20 pb-12 pt-4 border-t border-zinc-800/50"> <p class="text-zinc-300 text-lg leading-relaxed mb-8"> Nous Research has introduced NousCoder-14B, an open-source AI coding model that competes with larger proprietary systems, achieving a 67.87% accuracy rate on LiveCodeBench v6. This model was trained in just four days using 48 Nvidia B200 GPUs, showcasing a significant leap in AI-assisted software development. The release is notable for its transparency, as Nous Research has made the model weights, reinforcement learning environment, and training harness publicly available, allowing for reproducibility and further research by the AI community.

The emergence of NousCoder-14B highlights a pivotal moment in the AI ecosystem where open-source models are beginning to rival proprietary solutions. This development underscores the rapid evolution and fierce competition in AI-assisted coding, with Nous Research positioning itself as a formidable player by emphasizing transparency and community-driven innovation. The strategic impact is profound, as it challenges the dominance of proprietary models like Anthropic&#39;s Claude Code, potentially democratizing access to advanced AI coding tools and fostering innovation through open collaboration.

Experts recognize the potential of NousCoder-14B but also acknowledge the looming challenge of data scarcity in training AI models. The model&#39;s reliance on a vast dataset of competitive programming problems indicates that future advancements may hinge on synthetic data generation and more efficient learning algorithms. The trajectory of AI coding tools will likely involve training models to generate and solve their own problems, pushing the boundaries of AI capabilities and possibly surpassing human benchmarks in coding efficiency and creativity. </p> <a href="https://venturebeat.com/technology/nous-researchs-nouscoder-14b-is-an-open-source-coding-model-landing-right-in" target="_blank" class="inline-flex items-center gap-3 px-8 py-3.5 rounded-full bg-blue-600 text-white font-bold" onclick="event.stopPropagation();">
Read More →
</a> </div> </div> </div><div class="resource-card group relative w-full bg-zinc-900/20 border border-zinc-800/80 rounded-[3rem] overflow-hidden transition-all duration-500 cursor-pointer" data-expanded="false"> <div class="flex items-center justify-between p-8 md:p-10 w-full"> <div class="flex items-center gap-8"> <div class="shrink-0 px-4 py-1.5 rounded-full bg-blue-500/10 border border-blue-500/20 text-blue-400 font-mono text-[10px] font-bold uppercase tracking-widest"> LangChain </div> <h3 class="text-xl md:text-2xl font-bold text-white group-hover:text-blue-400"> In software, the code documents the app. In AI, the traces do. </h3> </div> <div class="icon-circle w-12 h-12 rounded-full bg-zinc-800 flex items-center justify-center transition-all duration-500 group-hover:bg-blue-600"> <svg xmlns="http://www.w3.org/2000/svg" class="w-6 h-6 text-white chevron-icon transition-transform duration-500" fill="none" viewBox="0 0 24 24" stroke="currentColor"> <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" d="M19 9l-7 7-7-7"></path> </svg> </div> </div> <div class="expand-wrapper overflow-hidden transition-all duration-700 ease-in-out"> <div class="px-10 md:px-20 pb-12 pt-4 border-t border-zinc-800/50"> <p class="text-zinc-300 text-lg leading-relaxed mb-8"> The article highlights a significant shift in the way AI agents are understood and managed compared to traditional software. In conventional software development, the code serves as the primary source of truth, guiding debugging, performance optimization, and feature understanding. However, in AI agents, the decision-making logic resides within the model at runtime, with traces—sequences of steps taken by the agent—serving as the new source of truth. This shift necessitates a focus on traces for debugging, testing, and optimizing AI systems, as the logic is not explicitly coded but rather emerges from the model&#39;s behavior during execution.

This paradigm shift has profound implications for the AI ecosystem, as it changes the way developers and researchers approach AI system management. Traditional methods of debugging and optimization, which rely heavily on code analysis, are no longer sufficient. Instead, the focus must be on analyzing traces to understand the agent&#39;s decision-making process, identify inefficiencies, and improve reasoning quality. This requires new tools and methodologies for trace analysis, as well as a continuous evaluation of AI agents in production to monitor for quality degradation and drift. The integration of trace analysis into the development workflow also transforms collaboration and product analytics, merging them into a unified process that considers both user and agent behavior.

The critical takeaway for experts is the necessity to adapt to this new reality where traces, rather than code, are central to understanding and improving AI agents. This shift presents challenges, such as the need for sophisticated trace analysis tools and the continuous evaluation of non-deterministic systems. However, it also offers opportunities to enhance AI agent performance and reliability by focusing on the actual decision-making processes. As the AI field continues to evolve, embracing this trace-centric approach will be crucial for developing robust, efficient, and effective AI systems. </p> <a href="https://www.blog.langchain.com/in-software-the-code-documents-the-app-in-ai-the-traces-do/" target="_blank" class="inline-flex items-center gap-3 px-8 py-3.5 rounded-full bg-blue-600 text-white font-bold" onclick="event.stopPropagation();">
Read More →
</a> </div> </div> </div> </div> </section> </main>  </body></html>